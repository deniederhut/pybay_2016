{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking for large but not big data\n",
    "## PyBay 2016\n",
    "### Memory management\n",
    "- build an intuition about what chunking is doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5451368119149018,-1.6996107290072229,7,9,0,0.8071396331247015,0.2724098588191702,1,1,1\n",
      "\n",
      "0.07107213865436755,-0.36836779235781386,2,0,0,-1.1125927116408099,0.036738078578910344,0,0,1\n",
      "\n",
      "-0.7418155746328328,1.467132160646872,3,6,1,0.0014421241396832412,0.2632936393069136,0,0,0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "\n",
    "with open('data.csv', 'r') as f:\n",
    "        for line in f:\n",
    "            if i < 3:\n",
    "                print line\n",
    "            i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_chunks(file_path, chunk_size):\n",
    "    with open(file_path, 'r') as f:\n",
    "        result = []\n",
    "        for line in f:\n",
    "            if len(result) == chunk_size:\n",
    "                yield result\n",
    "                result = []\n",
    "            result.append(convert_line(line))\n",
    "        else:\n",
    "                yield(result)\n",
    "                \n",
    "def convert_line(line):\n",
    "    return [float(item) for item in line.split(',') if item != '\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5451368119149018, -1.6996107290072229, 7.0, 9.0, 0.0, 0.8071396331247015, 0.2724098588191702, 1.0, 1.0, 1.0], [0.07107213865436755, -0.36836779235781386, 2.0, 0.0, 0.0, -1.1125927116408099, 0.036738078578910344, 0.0, 0.0, 1.0], [-0.7418155746328328, 1.467132160646872, 3.0, 6.0, 1.0, 0.0014421241396832412, 0.2632936393069136, 0.0, 0.0, 0.0], [-0.9465214125294857, 0.08530358707169183, 9.0, 3.0, 0.0, -0.3455951684668915, 0.44630107227479004, 0.0, 0.0, 0.0], [1.4152069939520378, 0.17971334523885543, 8.0, 5.0, 1.0, -0.03323317005008284, 0.10774269478053533, 0.0, 0.0, 1.0], [0.16099676181939104, 2.1077107542502733, 6.0, 1.0, 0.0, -0.9905723638316615, -0.7945683133938525, 0.0, 1.0, 0.0], [0.8937616981063747, 0.2758642561711137, 0.0, 0.0, 1.0, 3.183883988340478, -1.1713052134422954, 1.0, 0.0, 1.0], [-0.8706011275180053, 0.09621625919758102, 1.0, 8.0, 0.0, 0.9327173390472802, 0.1199176649737485, 1.0, 1.0, 1.0], [-0.49195346308732635, -1.0932728833707896, 2.0, 9.0, 1.0, -0.9262034137114997, -1.307305614274532, 1.0, 1.0, 0.0], [-0.31832419385038724, 1.3776122723734814, 5.0, 2.0, 1.0, -0.40458180528661436, -0.09991193817619384, 1.0, 0.0, 1.0]]\n",
      "[[-1.9797422199906094, 0.20484950245674302, 3.0, 1.0, 1.0, -0.5088582377934716, 1.8231215002596732, 1.0, 1.0, 1.0], [-1.3241358458039347, 0.9453111447841026, 2.0, 4.0, 0.0, 0.7225352158919987, -2.1213326923203866, 0.0, 1.0, 0.0], [-0.012935206798529787, 0.565163924665128, 2.0, 4.0, 0.0, 0.4532647099706649, -0.8127234001332843, 0.0, 1.0, 0.0], [-0.6711755995363189, 0.09480681112060167, 3.0, 4.0, 1.0, 0.4277222186281182, 0.38415369251295606, 1.0, 0.0, 1.0], [-0.4538060508646856, 0.797285005299077, 6.0, 7.0, 1.0, -0.6406404789562519, -0.33297084341873273, 0.0, 0.0, 0.0], [0.5784110385861118, -0.48676816233852416, 7.0, 3.0, 0.0, -0.8136929368038452, 0.2681101498233064, 1.0, 0.0, 1.0], [1.5360125284931099, -0.6850575105882283, 9.0, 4.0, 0.0, 2.504005311400736, -1.4554951411892434, 0.0, 0.0, 1.0], [0.19211968704883547, -0.036706169211782574, 3.0, 1.0, 1.0, -1.0287797181531717, 1.1113895783255507, 1.0, 1.0, 1.0], [1.0182868091248582, -0.5775767346641175, 2.0, 8.0, 0.0, 0.2872478539375859, -1.1860106415998948, 1.0, 0.0, 1.0], [0.08750511163578463, 1.400576407188057, 2.0, 4.0, 0.0, 0.34673556415524887, -0.8657461909953054, 0.0, 0.0, 0.0]]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for chunk in read_chunks('data.csv', 10):\n",
    "    if i < 2:\n",
    "        print chunk\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1  2  3  4         5         6  7  8  9\n",
      "0  0.545137 -1.699611  7  9  0  0.807140  0.272410  1  1  1\n",
      "1  0.071072 -0.368368  2  0  0 -1.112593  0.036738  0  0  1\n",
      "2 -0.741816  1.467132  3  6  1  0.001442  0.263294  0  0  0\n",
      "3 -0.946521  0.085304  9  3  0 -0.345595  0.446301  0  0  0\n",
      "4  1.415207  0.179713  8  5  1 -0.033233  0.107743  0  0  1\n",
      "5  0.160997  2.107711  6  1  0 -0.990572 -0.794568  0  1  0\n",
      "6  0.893762  0.275864  0  0  1  3.183884 -1.171305  1  0  1\n",
      "7 -0.870601  0.096216  1  8  0  0.932717  0.119918  1  1  1\n",
      "8 -0.491953 -1.093273  2  9  1 -0.926203 -1.307306  1  1  0\n",
      "9 -0.318324  1.377612  5  2  1 -0.404582 -0.099912  1  0  1\n",
      "          0         1  2  3  4         5         6  7  8  9\n",
      "0 -1.979742  0.204850  3  1  1 -0.508858  1.823122  1  1  1\n",
      "1 -1.324136  0.945311  2  4  0  0.722535 -2.121333  0  1  0\n",
      "2 -0.012935  0.565164  2  4  0  0.453265 -0.812723  0  1  0\n",
      "3 -0.671176  0.094807  3  4  1  0.427722  0.384154  1  0  1\n",
      "4 -0.453806  0.797285  6  7  1 -0.640640 -0.332971  0  0  0\n",
      "5  0.578411 -0.486768  7  3  0 -0.813693  0.268110  1  0  1\n",
      "6  1.536013 -0.685058  9  4  0  2.504005 -1.455495  0  0  1\n",
      "7  0.192120 -0.036706  3  1  1 -1.028780  1.111390  1  1  1\n",
      "8  1.018287 -0.577577  2  8  0  0.287248 -1.186011  1  0  1\n",
      "9  0.087505  1.400576  2  4  0  0.346736 -0.865746  0  0  0\n"
     ]
    }
   ],
   "source": [
    "generator = pd.read_csv('data.csv', header=None, chunksize=10) #returns a generator\n",
    "i = 0\n",
    "for chunk in generator:\n",
    "    if i < 2:\n",
    "        print chunk\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Chunked data in hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'data']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = h5py.File('demo.hdf5', 'r+')\n",
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.45136812e-01,  -1.69961073e+00,   7.00000000e+00,\n",
       "          9.00000000e+00,   0.00000000e+00,   8.07139633e-01,\n",
       "          2.72409859e-01,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00],\n",
       "       [  7.10721387e-02,  -3.68367792e-01,   2.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,  -1.11259271e+00,\n",
       "          3.67380786e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00],\n",
       "       [ -7.41815575e-01,   1.46713216e+00,   3.00000000e+00,\n",
       "          6.00000000e+00,   1.00000000e+00,   1.44212414e-03,\n",
       "          2.63293639e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['data'][0:3]  # slice through object on disk instead of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['data'].chunks # entire size of dataframe on disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"test\": shape (10000,), type \"<i8\">"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.create_dataset('test', data=range(10000), chunks=(10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['test'].chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intelligent reading with databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3 as sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connection = sql.connect('demo.db')\n",
    "\n",
    "c = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.5451368119149018, -1.6996107290072229, 7, 9, 0, 0.8071396331247015, 0.2724098588191702, 1, 1, 1)\n",
      "(1, 0.07107213865436755, -0.36836779235781386, 2, 0, 0, -1.1125927116408099, 0.036738078578910344, 0, 0, 1)\n",
      "(2, -0.7418155746328328, 1.467132160646872, 3, 6, 1, 0.0014421241396832412, 0.2632936393069136, 0, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "c.execute('select * from data')\n",
    "\n",
    "i = 0\n",
    "for row in c.fetchmany(size=10):\n",
    "    if i < 3: \n",
    "        print row\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intra-routine parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.array(pd.read_csv('data.csv', header=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with matrix algebra to show how fast numpy is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dumb_add(x, y):\n",
    "    for row_index in range(len(x)):\n",
    "        for col_index in range(len(x[0])):\n",
    "            x[row_index][col_index] += y[row_index][col_index]\n",
    "    return x\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 1.05 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit dumb_add(data, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 32.86 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000000 loops, best of 3: 1.21 Âµs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit data + data  ## now do the same thing with numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to parallelize within a process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dask import dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dd.Series<datafra..., npartitions=1>\n"
     ]
    }
   ],
   "source": [
    "data = dataframe.read_csv('data.csv', header=None)\n",
    "col_max = data.max()\n",
    "print col_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bytes_read_csv-69dd0520c52961dd00da4ccbced7584c': (<function apply>,\n",
       "  <function dask.dataframe.csv.bytes_read_csv>,\n",
       "  ['read-file-block-d5e2fdeb9e825be98d4b7a8ce9bd9622-0',\n",
       "   '',\n",
       "   (dict, [['header', None]]),\n",
       "   (dict,\n",
       "    [[0, dtype('float64')],\n",
       "     [1, dtype('float64')],\n",
       "     [2, dtype('int64')],\n",
       "     [3, dtype('int64')],\n",
       "     [4, dtype('int64')],\n",
       "     [5, dtype('float64')],\n",
       "     [6, dtype('float64')],\n",
       "     [7, dtype('int64')],\n",
       "     [8, dtype('int64')],\n",
       "     [9, dtype('int64')]]),\n",
       "   (list, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9])],\n",
       "  (dict, [['write_header', False], ['enforce', False]])),\n",
       " 'read-file-block-d5e2fdeb9e825be98d4b7a8ce9bd9622-0': (<function dask.bytes.local.read_block_from_file>,\n",
       "  'data.csv',\n",
       "  0,\n",
       "  64000000,\n",
       "  '\\n',\n",
       "  None),\n",
       " ('dataframe-max--first-04edc869a5e065dcef1a4f2875158042',\n",
       "  0): (<function apply>, <function dask.dataframe.core._max>, [('from-delayed-01300be2f1f447ed383b5523c6b07192',\n",
       "    0)], {'axis': 0, 'skipna': True}),\n",
       " ('dataframe-max--second-04edc869a5e065dcef1a4f2875158042',\n",
       "  0): (<function apply>, <function dask.dataframe.core.aggregate>, [(<function dask.dataframe.core._concat>,\n",
       "    (list,\n",
       "     [('dataframe-max--first-04edc869a5e065dcef1a4f2875158042',\n",
       "       0)]))], {'axis': 0,\n",
       "   'skipna': True}),\n",
       " ('from-delayed-01300be2f1f447ed383b5523c6b07192',\n",
       "  0): 'bytes_read_csv-69dd0520c52961dd00da4ccbced7584c'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_max.dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2.936829\n",
       "1    2.107711\n",
       "2    9.000000\n",
       "3    9.000000\n",
       "4    1.000000\n",
       "5    3.183884\n",
       "6    2.280348\n",
       "7    1.000000\n",
       "8    1.000000\n",
       "9    1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_max.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelizing at the job level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from app import summarize_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summarize_file('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#delayed task processing\n",
    "summarize_file.delay('data.csv', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## start up rabbitmq\n",
    "## then use celery to start the app we just created using 'celery -A ...'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
